{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yesindeed/anaconda3/envs/vlmbenchmark/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"BoKelvin/SLAKE\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1033\n",
      "2094\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for d in ds:\n",
    "    if d[\"q_lang\"] != \"en\":\n",
    "        count += 1\n",
    "\n",
    "print(count)\n",
    "\n",
    "print(len(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img_name': 'xmlab102/source.jpg',\n",
       " 'location': 'Lung',\n",
       " 'answer': 'CT',\n",
       " 'modality': 'CT',\n",
       " 'base_type': 'vqa',\n",
       " 'answer_type': 'OPEN',\n",
       " 'question': 'What modality is used to take this image?',\n",
       " 'qid': 11934,\n",
       " 'content_type': 'Modality',\n",
       " 'triple': ['vhead', '_', '_'],\n",
       " 'img_id': 102,\n",
       " 'q_lang': 'en'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'must', 'numbers,', 'or', 'batch', 'tensors,', 'default_collate:', 'numpy', 'arrays,', 'dicts', 'lists', 'contain'}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "contractions = {\n",
    "    \"aint\": \"ain't\",\n",
    "    \"arent\": \"aren't\",\n",
    "    \"cant\": \"can't\",\n",
    "    \"couldve\": \"could've\",\n",
    "    \"couldnt\": \"couldn't\",\n",
    "    \"couldn'tve\": \"couldn't've\",\n",
    "    \"couldnt've\": \"couldn't've\",\n",
    "    \"didnt\": \"didn't\",\n",
    "    \"doesnt\": \"doesn't\",\n",
    "    \"dont\": \"don't\",\n",
    "    \"hadnt\": \"hadn't\",\n",
    "    \"hadnt've\": \"hadn't've\",\n",
    "    \"hadn'tve\": \"hadn't've\",\n",
    "    \"hasnt\": \"hasn't\",\n",
    "    \"havent\": \"haven't\",\n",
    "    \"hed\": \"he'd\",\n",
    "    \"hed've\": \"he'd've\",\n",
    "    \"he'dve\": \"he'd've\",\n",
    "    \"hes\": \"he's\",\n",
    "    \"howd\": \"how'd\",\n",
    "    \"howll\": \"how'll\",\n",
    "    \"hows\": \"how's\",\n",
    "    \"Id've\": \"I'd've\",\n",
    "    \"I'dve\": \"I'd've\",\n",
    "    \"Im\": \"I'm\",\n",
    "    \"Ive\": \"I've\",\n",
    "    \"isnt\": \"isn't\",\n",
    "    \"itd\": \"it'd\",\n",
    "    \"itd've\": \"it'd've\",\n",
    "    \"it'dve\": \"it'd've\",\n",
    "    \"itll\": \"it'll\",\n",
    "    \"let's\": \"let's\",\n",
    "    \"maam\": \"ma'am\",\n",
    "    \"mightnt\": \"mightn't\",\n",
    "    \"mightnt've\": \"mightn't've\",\n",
    "    \"mightn'tve\": \"mightn't've\",\n",
    "    \"mightve\": \"might've\",\n",
    "    \"mustnt\": \"mustn't\",\n",
    "    \"mustve\": \"must've\",\n",
    "    \"neednt\": \"needn't\",\n",
    "    \"notve\": \"not've\",\n",
    "    \"oclock\": \"o'clock\",\n",
    "    \"oughtnt\": \"oughtn't\",\n",
    "    \"ow's'at\": \"'ow's'at\",\n",
    "    \"'ows'at\": \"'ow's'at\",\n",
    "    \"'ow'sat\": \"'ow's'at\",\n",
    "    \"shant\": \"shan't\",\n",
    "    \"shed've\": \"she'd've\",\n",
    "    \"she'dve\": \"she'd've\",\n",
    "    \"she's\": \"she's\",\n",
    "    \"shouldve\": \"should've\",\n",
    "    \"shouldnt\": \"shouldn't\",\n",
    "    \"shouldnt've\": \"shouldn't've\",\n",
    "    \"shouldn'tve\": \"shouldn't've\",\n",
    "    \"somebody'd\": \"somebodyd\",\n",
    "    \"somebodyd've\": \"somebody'd've\",\n",
    "    \"somebody'dve\": \"somebody'd've\",\n",
    "    \"somebodyll\": \"somebody'll\",\n",
    "    \"somebodys\": \"somebody's\",\n",
    "    \"someoned\": \"someone'd\",\n",
    "    \"someoned've\": \"someone'd've\",\n",
    "    \"someone'dve\": \"someone'd've\",\n",
    "    \"someonell\": \"someone'll\",\n",
    "    \"someones\": \"someone's\",\n",
    "    \"somethingd\": \"something'd\",\n",
    "    \"somethingd've\": \"something'd've\",\n",
    "    \"something'dve\": \"something'd've\",\n",
    "    \"somethingll\": \"something'll\",\n",
    "    \"thats\": \"that's\",\n",
    "    \"thered\": \"there'd\",\n",
    "    \"thered've\": \"there'd've\",\n",
    "    \"there'dve\": \"there'd've\",\n",
    "    \"therere\": \"there're\",\n",
    "    \"theres\": \"there's\",\n",
    "    \"theyd\": \"they'd\",\n",
    "    \"theyd've\": \"they'd've\",\n",
    "    \"they'dve\": \"they'd've\",\n",
    "    \"theyll\": \"they'll\",\n",
    "    \"theyre\": \"they're\",\n",
    "    \"theyve\": \"they've\",\n",
    "    \"twas\": \"'twas\",\n",
    "    \"wasnt\": \"wasn't\",\n",
    "    \"wed've\": \"we'd've\",\n",
    "    \"we'dve\": \"we'd've\",\n",
    "    \"weve\": \"we've\",\n",
    "    \"werent\": \"weren't\",\n",
    "    \"whatll\": \"what'll\",\n",
    "    \"whatre\": \"what're\",\n",
    "    \"whats\": \"what's\",\n",
    "    \"whatve\": \"what've\",\n",
    "    \"whens\": \"when's\",\n",
    "    \"whered\": \"where'd\",\n",
    "    \"wheres\": \"where's\",\n",
    "    \"whereve\": \"where've\",\n",
    "    \"whod\": \"who'd\",\n",
    "    \"whod've\": \"who'd've\",\n",
    "    \"who'dve\": \"who'd've\",\n",
    "    \"wholl\": \"who'll\",\n",
    "    \"whos\": \"who's\",\n",
    "    \"whove\": \"who've\",\n",
    "    \"whyll\": \"why'll\",\n",
    "    \"whyre\": \"why're\",\n",
    "    \"whys\": \"why's\",\n",
    "    \"wont\": \"won't\",\n",
    "    \"wouldve\": \"would've\",\n",
    "    \"wouldnt\": \"wouldn't\",\n",
    "    \"wouldnt've\": \"wouldn't've\",\n",
    "    \"wouldn'tve\": \"wouldn't've\",\n",
    "    \"yall\": \"y'all\",\n",
    "    \"yall'll\": \"y'all'll\",\n",
    "    \"y'allll\": \"y'all'll\",\n",
    "    \"yall'd've\": \"y'all'd've\",\n",
    "    \"y'alld've\": \"y'all'd've\",\n",
    "    \"y'all'dve\": \"y'all'd've\",\n",
    "    \"youd\": \"you'd\",\n",
    "    \"youd've\": \"you'd've\",\n",
    "    \"you'dve\": \"you'd've\",\n",
    "    \"youll\": \"you'll\",\n",
    "    \"youre\": \"you're\",\n",
    "    \"youve\": \"you've\",\n",
    "}\n",
    "\n",
    "manual_map = {\n",
    "    \"none\": \"0\",\n",
    "    \"zero\": \"0\",\n",
    "    \"one\": \"1\",\n",
    "    \"two\": \"2\",\n",
    "    \"three\": \"3\",\n",
    "    \"four\": \"4\",\n",
    "    \"five\": \"5\",\n",
    "    \"six\": \"6\",\n",
    "    \"seven\": \"7\",\n",
    "    \"eight\": \"8\",\n",
    "    \"nine\": \"9\",\n",
    "    \"ten\": \"10\",\n",
    "}\n",
    "articles = [\"a\", \"an\", \"the\"]\n",
    "period_strip = re.compile(r\"(?!<=\\d)(\\.)(?!\\d)\")  # noqa\n",
    "comma_strip = re.compile(r\"(\\d)(\\,)(\\d)\")  # noqa\n",
    "punct = [\n",
    "    \";\",\n",
    "    r\"/\",\n",
    "    \"[\",\n",
    "    \"]\",\n",
    "    '\"',\n",
    "    \"{\",\n",
    "    \"}\",\n",
    "    \"(\",\n",
    "    \")\",\n",
    "    \"=\",\n",
    "    \"+\",\n",
    "    \"\\\\\",\n",
    "    \"_\",\n",
    "    \"-\",\n",
    "    \">\",\n",
    "    \"<\",\n",
    "    \"@\",\n",
    "    \"`\",\n",
    "    \",\",\n",
    "    \"?\",\n",
    "    \"!\",\n",
    "]\n",
    "\n",
    "\n",
    "def clean_str(token):\n",
    "    \"\"\"Cleans a string (removes punctuation, lowers...).\n",
    "\n",
    "    Args:\n",
    "        token: The string to clean.\n",
    "\n",
    "    Returns:\n",
    "        The cleaned string.\n",
    "    \"\"\"\n",
    "    token = token.lower()\n",
    "    _token = token\n",
    "    for p in punct:\n",
    "        if (p + \" \" in token or \" \" + p in token) or (re.search(comma_strip, token) is not None):\n",
    "            _token = _token.replace(p, \"\")\n",
    "        else:\n",
    "            _token = _token.replace(p, \" \")\n",
    "    token = period_strip.sub(\"\", _token, re.UNICODE)\n",
    "\n",
    "    _token = []\n",
    "    temp = token.lower().split()\n",
    "    for word in temp:\n",
    "        word = manual_map.setdefault(word, word)\n",
    "        if word not in articles:\n",
    "            _token.append(word)\n",
    "    for i, word in enumerate(_token):\n",
    "        if word in contractions:\n",
    "            _token[i] = contractions[word]\n",
    "    token = \" \".join(_token)\n",
    "    token = token.replace(\",\", \"\")\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default collate: batch must contain tensors numpy arrays numbers dicts or lists\n",
      "{'must', 'numbers,', 'or', 'batch', 'tensors,', 'default_collate:', 'numpy', 'arrays,', 'dicts', 'lists', 'contain'}\n"
     ]
    }
   ],
   "source": [
    "def process_tokens(text):\n",
    "    tokenized_text = set(text.split())\n",
    "    tokenized_text.discard(\"\")\n",
    "    return tokenized_text\n",
    "\n",
    "\n",
    "text = \"default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists\"\n",
    "\n",
    "print(clean_str(text))\n",
    "print(process_tokens(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1_fmeasure': tensor(0.7500), 'rouge1_precision': tensor(0.7500), 'rouge1_recall': tensor(0.7500), 'rouge2_fmeasure': tensor(0.), 'rouge2_precision': tensor(0.), 'rouge2_recall': tensor(0.), 'rougeL_fmeasure': tensor(0.5000), 'rougeL_precision': tensor(0.5000), 'rougeL_recall': tensor(0.5000), 'rougeLsum_fmeasure': tensor(0.5000), 'rougeLsum_precision': tensor(0.5000), 'rougeLsum_recall': tensor(0.5000)}\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics.functional.text import bleu_score, rouge_score\n",
    "\n",
    "preds = \"My name is John\"\n",
    "target = \"Is your name John\"\n",
    "\n",
    "bleu1 = bleu_score([preds], [[target]], n_gram=1).item()\n",
    "\n",
    "print(rouge_score(preds, target))\n",
    "\n",
    "print(bleu1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(\"bleu1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   key  value\n",
       "0    1      2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d_ = {\"key\": [1], \"value\": [2]}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(d_)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlmbenchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
