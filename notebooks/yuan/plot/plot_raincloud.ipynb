{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm, mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>dataset</th>\n",
       "      <th>model_type</th>\n",
       "      <th>trainable_module</th>\n",
       "      <th>path</th>\n",
       "      <th>have_eval_result</th>\n",
       "      <th>have_prediction</th>\n",
       "      <th>have_gpt_score</th>\n",
       "      <th>model_name</th>\n",
       "      <th>...</th>\n",
       "      <th>exact_match_overall</th>\n",
       "      <th>recall_overall</th>\n",
       "      <th>precision_overall</th>\n",
       "      <th>f1_overall</th>\n",
       "      <th>exact_match_closed</th>\n",
       "      <th>recall_closed</th>\n",
       "      <th>precision_closed</th>\n",
       "      <th>f1_score_closed</th>\n",
       "      <th>accuracy_closed</th>\n",
       "      <th>gpt_score_open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qwen2-VL</td>\n",
       "      <td>vqa</td>\n",
       "      <td>SLAKE</td>\n",
       "      <td>general</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vqa/SLAKE/Qwen2-VL/eval_seed0/Qwen2-VL-7B-Inst...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Qwen2-VL-7B-Instruct</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285276</td>\n",
       "      <td>0.624306</td>\n",
       "      <td>0.292802</td>\n",
       "      <td>0.318349</td>\n",
       "      <td>0.658153</td>\n",
       "      <td>0.774038</td>\n",
       "      <td>0.661506</td>\n",
       "      <td>0.668063</td>\n",
       "      <td>0.778846</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Qwen25-VL</td>\n",
       "      <td>vqa</td>\n",
       "      <td>SLAKE</td>\n",
       "      <td>general</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vqa/SLAKE/Qwen25-VL/eval_seed0/Qwen2.5-VL-7B-I...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Qwen2.5-VL-7B-Instruct</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252990</td>\n",
       "      <td>0.596551</td>\n",
       "      <td>0.260487</td>\n",
       "      <td>0.274167</td>\n",
       "      <td>0.627367</td>\n",
       "      <td>0.747596</td>\n",
       "      <td>0.629623</td>\n",
       "      <td>0.633801</td>\n",
       "      <td>0.754808</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gemma3</td>\n",
       "      <td>vqa</td>\n",
       "      <td>SLAKE</td>\n",
       "      <td>general</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vqa/SLAKE/Gemma3/eval_seed0/gemma-3-4b-it</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>gemma-3-4b-it</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032464</td>\n",
       "      <td>0.525746</td>\n",
       "      <td>0.038177</td>\n",
       "      <td>0.056352</td>\n",
       "      <td>0.070822</td>\n",
       "      <td>0.657252</td>\n",
       "      <td>0.073086</td>\n",
       "      <td>0.097527</td>\n",
       "      <td>0.721154</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MedGemma</td>\n",
       "      <td>vqa</td>\n",
       "      <td>SLAKE</td>\n",
       "      <td>medical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vqa/SLAKE/MedGemma/eval_seed0/medgemma-4b-it</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>medgemma-4b-it</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243252</td>\n",
       "      <td>0.575250</td>\n",
       "      <td>0.250568</td>\n",
       "      <td>0.265892</td>\n",
       "      <td>0.597256</td>\n",
       "      <td>0.725962</td>\n",
       "      <td>0.599219</td>\n",
       "      <td>0.604106</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>InternVL3</td>\n",
       "      <td>vqa</td>\n",
       "      <td>SLAKE</td>\n",
       "      <td>general</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vqa/SLAKE/InternVL3/eval_seed0/InternVL3-8B-hf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>InternVL3-8B-hf</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093509</td>\n",
       "      <td>0.601884</td>\n",
       "      <td>0.102192</td>\n",
       "      <td>0.128382</td>\n",
       "      <td>0.209306</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.212497</td>\n",
       "      <td>0.238663</td>\n",
       "      <td>0.745192</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>VILA</td>\n",
       "      <td>vqa</td>\n",
       "      <td>VQA-RAD</td>\n",
       "      <td>general</td>\n",
       "      <td>ML</td>\n",
       "      <td>vqa/VQA-RAD/VILA1.5/eval_seed0/1epoch-lora8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train_lora_ML_seed42_vila</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485218</td>\n",
       "      <td>0.470030</td>\n",
       "      <td>0.485218</td>\n",
       "      <td>0.472669</td>\n",
       "      <td>0.637450</td>\n",
       "      <td>0.637450</td>\n",
       "      <td>0.637450</td>\n",
       "      <td>0.637450</td>\n",
       "      <td>0.637450</td>\n",
       "      <td>44.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>VILA-M3</td>\n",
       "      <td>vqa</td>\n",
       "      <td>VQA-RAD</td>\n",
       "      <td>medical</td>\n",
       "      <td>ML</td>\n",
       "      <td>vqa/VQA-RAD/VILA-M3/eval_seed0/1epoch-lora8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train_lora_ML_seed42_vila_m3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370001</td>\n",
       "      <td>0.420918</td>\n",
       "      <td>0.370242</td>\n",
       "      <td>0.379170</td>\n",
       "      <td>0.537849</td>\n",
       "      <td>0.537849</td>\n",
       "      <td>0.537849</td>\n",
       "      <td>0.537849</td>\n",
       "      <td>0.537849</td>\n",
       "      <td>46.795000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Lingshu</td>\n",
       "      <td>vqa</td>\n",
       "      <td>Harvard-FairVLMed10k</td>\n",
       "      <td>medical</td>\n",
       "      <td>ML</td>\n",
       "      <td>vqa/Harvard-FairVLMed10k/Lingshu/eval_seed0/1e...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train_lora_ML_seed42_lingshu</td>\n",
       "      <td>...</td>\n",
       "      <td>0.576751</td>\n",
       "      <td>0.591223</td>\n",
       "      <td>0.580907</td>\n",
       "      <td>0.580271</td>\n",
       "      <td>0.738978</td>\n",
       "      <td>0.738978</td>\n",
       "      <td>0.738978</td>\n",
       "      <td>0.738978</td>\n",
       "      <td>0.738978</td>\n",
       "      <td>57.234234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>VILA</td>\n",
       "      <td>vqa</td>\n",
       "      <td>Harvard-FairVLMed10k</td>\n",
       "      <td>general</td>\n",
       "      <td>ML</td>\n",
       "      <td>vqa/Harvard-FairVLMed10k/VILA1.5/eval_seed0/1e...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train_lora_ML_seed42_vila</td>\n",
       "      <td>...</td>\n",
       "      <td>0.662567</td>\n",
       "      <td>0.638053</td>\n",
       "      <td>0.668046</td>\n",
       "      <td>0.647041</td>\n",
       "      <td>0.811122</td>\n",
       "      <td>0.811122</td>\n",
       "      <td>0.811122</td>\n",
       "      <td>0.811122</td>\n",
       "      <td>0.811122</td>\n",
       "      <td>56.039540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>VILA-M3</td>\n",
       "      <td>vqa</td>\n",
       "      <td>Harvard-FairVLMed10k</td>\n",
       "      <td>medical</td>\n",
       "      <td>ML</td>\n",
       "      <td>vqa/Harvard-FairVLMed10k/VILA-M3/eval_seed0/1e...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train_lora_ML_seed42_vila_m3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232432</td>\n",
       "      <td>0.666744</td>\n",
       "      <td>0.280618</td>\n",
       "      <td>0.338911</td>\n",
       "      <td>0.097379</td>\n",
       "      <td>0.802104</td>\n",
       "      <td>0.137019</td>\n",
       "      <td>0.229663</td>\n",
       "      <td>0.821142</td>\n",
       "      <td>54.498498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        model task               dataset model_type trainable_module  \\\n",
       "0    Qwen2-VL  vqa                 SLAKE    general              NaN   \n",
       "1   Qwen25-VL  vqa                 SLAKE    general              NaN   \n",
       "2      Gemma3  vqa                 SLAKE    general              NaN   \n",
       "3    MedGemma  vqa                 SLAKE    medical              NaN   \n",
       "4   InternVL3  vqa                 SLAKE    general              NaN   \n",
       "..        ...  ...                   ...        ...              ...   \n",
       "68       VILA  vqa               VQA-RAD    general               ML   \n",
       "69    VILA-M3  vqa               VQA-RAD    medical               ML   \n",
       "70    Lingshu  vqa  Harvard-FairVLMed10k    medical               ML   \n",
       "71       VILA  vqa  Harvard-FairVLMed10k    general               ML   \n",
       "72    VILA-M3  vqa  Harvard-FairVLMed10k    medical               ML   \n",
       "\n",
       "                                                 path  have_eval_result  \\\n",
       "0   vqa/SLAKE/Qwen2-VL/eval_seed0/Qwen2-VL-7B-Inst...                 1   \n",
       "1   vqa/SLAKE/Qwen25-VL/eval_seed0/Qwen2.5-VL-7B-I...                 1   \n",
       "2           vqa/SLAKE/Gemma3/eval_seed0/gemma-3-4b-it                 1   \n",
       "3        vqa/SLAKE/MedGemma/eval_seed0/medgemma-4b-it                 1   \n",
       "4      vqa/SLAKE/InternVL3/eval_seed0/InternVL3-8B-hf                 1   \n",
       "..                                                ...               ...   \n",
       "68        vqa/VQA-RAD/VILA1.5/eval_seed0/1epoch-lora8                 1   \n",
       "69        vqa/VQA-RAD/VILA-M3/eval_seed0/1epoch-lora8                 1   \n",
       "70  vqa/Harvard-FairVLMed10k/Lingshu/eval_seed0/1e...                 1   \n",
       "71  vqa/Harvard-FairVLMed10k/VILA1.5/eval_seed0/1e...                 1   \n",
       "72  vqa/Harvard-FairVLMed10k/VILA-M3/eval_seed0/1e...                 1   \n",
       "\n",
       "    have_prediction  have_gpt_score                    model_name  ...  \\\n",
       "0                 1               0          Qwen2-VL-7B-Instruct  ...   \n",
       "1                 1               0        Qwen2.5-VL-7B-Instruct  ...   \n",
       "2                 1               0                 gemma-3-4b-it  ...   \n",
       "3                 1               0                medgemma-4b-it  ...   \n",
       "4                 1               0               InternVL3-8B-hf  ...   \n",
       "..              ...             ...                           ...  ...   \n",
       "68                1               1     train_lora_ML_seed42_vila  ...   \n",
       "69                1               1  train_lora_ML_seed42_vila_m3  ...   \n",
       "70                1               1  train_lora_ML_seed42_lingshu  ...   \n",
       "71                1               1     train_lora_ML_seed42_vila  ...   \n",
       "72                1               1  train_lora_ML_seed42_vila_m3  ...   \n",
       "\n",
       "   exact_match_overall  recall_overall  precision_overall  f1_overall  \\\n",
       "0             0.285276        0.624306           0.292802    0.318349   \n",
       "1             0.252990        0.596551           0.260487    0.274167   \n",
       "2             0.032464        0.525746           0.038177    0.056352   \n",
       "3             0.243252        0.575250           0.250568    0.265892   \n",
       "4             0.093509        0.601884           0.102192    0.128382   \n",
       "..                 ...             ...                ...         ...   \n",
       "68            0.485218        0.470030           0.485218    0.472669   \n",
       "69            0.370001        0.420918           0.370242    0.379170   \n",
       "70            0.576751        0.591223           0.580907    0.580271   \n",
       "71            0.662567        0.638053           0.668046    0.647041   \n",
       "72            0.232432        0.666744           0.280618    0.338911   \n",
       "\n",
       "    exact_match_closed  recall_closed  precision_closed  f1_score_closed  \\\n",
       "0             0.658153       0.774038          0.661506         0.668063   \n",
       "1             0.627367       0.747596          0.629623         0.633801   \n",
       "2             0.070822       0.657252          0.073086         0.097527   \n",
       "3             0.597256       0.725962          0.599219         0.604106   \n",
       "4             0.209306       0.711538          0.212497         0.238663   \n",
       "..                 ...            ...               ...              ...   \n",
       "68            0.637450       0.637450          0.637450         0.637450   \n",
       "69            0.537849       0.537849          0.537849         0.537849   \n",
       "70            0.738978       0.738978          0.738978         0.738978   \n",
       "71            0.811122       0.811122          0.811122         0.811122   \n",
       "72            0.097379       0.802104          0.137019         0.229663   \n",
       "\n",
       "    accuracy_closed  gpt_score_open  \n",
       "0          0.778846             NaN  \n",
       "1          0.754808             NaN  \n",
       "2          0.721154             NaN  \n",
       "3          0.769231             NaN  \n",
       "4          0.745192             NaN  \n",
       "..              ...             ...  \n",
       "68         0.637450       44.820000  \n",
       "69         0.537849       46.795000  \n",
       "70         0.738978       57.234234  \n",
       "71         0.811122       56.039540  \n",
       "72         0.821142       54.498498  \n",
       "\n",
       "[73 rows x 36 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_root = \"/media/yesindeed/DATADRIVE1/mount/remote_cse/experiments/med_vlm_benchmark/merged\"\n",
    "\n",
    "df_results = pd.read_csv(os.path.join(exp_root, \"results.csv\"))\n",
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model\n",
       "Qwen25-VL    8\n",
       "LLaVA-1.5    8\n",
       "VILA-M3      8\n",
       "VILA         8\n",
       "Lingshu      8\n",
       "LLaVA-Med    8\n",
       "Qwen2-VL     7\n",
       "Gemma3       7\n",
       "InternVL3    7\n",
       "MedGemma     4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results[\"model\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raincloud(\n",
    "    df_group1, df_group2, dataset=None, filename=\"raincloud\", legend_label=None, target_metric=\"accuracy_closed\"\n",
    "):\n",
    "    if dataset is not None:\n",
    "        df_group1 = df_group1.loc[df_group1[\"dataset\"] == dataset]\n",
    "        df_group2 = df_group2.loc[df_group2[\"dataset\"] == dataset]\n",
    "\n",
    "    df_plot = pd.concat([df_group1, df_group2]).reset_index(drop=True)\n",
    "\n",
    "    plt.figure(figsize=(8, 3))\n",
    "\n",
    "    ax = sns.violinplot(\n",
    "        x=target_metric,\n",
    "        y=\"task\",\n",
    "        data=df_group1,\n",
    "        inner=None,\n",
    "        split=True,\n",
    "        linewidth=1,\n",
    "        color=(0.19460784, 0.45343137, 0.63284314),\n",
    "    )\n",
    "    for violin in ax.collections:\n",
    "        facecolor = violin.get_facecolor()\n",
    "        violin.set_facecolor((*facecolor[:3], 0.4))\n",
    "    ax = sns.violinplot(\n",
    "        x=target_metric,\n",
    "        y=\"task\",\n",
    "        data=df_group2,\n",
    "        inner=None,\n",
    "        split=True,\n",
    "        linewidth=1,\n",
    "        color=[0.88186275, 0.50539216, 0.17303922],\n",
    "    )\n",
    "    for violin in ax.collections:\n",
    "        facecolor = violin.get_facecolor()\n",
    "        violin.set_facecolor((*facecolor[:3], 0.4))\n",
    "\n",
    "    ax = sns.boxplot(\n",
    "        x=target_metric,\n",
    "        y=\"task\",\n",
    "        data=df_plot,\n",
    "        # whis=1.5,\n",
    "        width=0.15,\n",
    "        gap=0.3,\n",
    "        hue=\"model_type\",\n",
    "        hue_order=[\"general\", \"medical\"],\n",
    "    )\n",
    "\n",
    "    if legend_label is not None:\n",
    "        handles, _ = ax.get_legend_handles_labels()  # Get the artists.\n",
    "        ax.legend(handles, legend_label, loc=\"best\")\n",
    "\n",
    "    plt.savefig(\n",
    "        f\"raincloud_plot/{filename}_{target_metric}.png\", bbox_inches=\"tight\")\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def stat_test(df_group1, df_group2, dataset=None, target_metric=\"accuracy_closed\", alternative=\"greater\"):\n",
    "    if dataset is not None:\n",
    "        df_group1 = df_group1.loc[df_group1[\"dataset\"] == dataset]\n",
    "        df_group2 = df_group2.loc[df_group2[\"dataset\"] == dataset]\n",
    "\n",
    "    U, p = mannwhitneyu(\n",
    "        df_group1[target_metric].tolist(), df_group2[target_metric].tolist(), alternative=alternative, method=\"auto\"\n",
    "    )\n",
    "\n",
    "    prob = U / (len(df_group1[target_metric].tolist())\n",
    "                * len(df_group2[target_metric].tolist()))\n",
    "\n",
    "    return U, p, prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group1 = df_results.loc[(df_results[\"model_type\"] == \"general\") & (\n",
    "    df_results[\"trainable_module\"] != \"ML\")]\n",
    "df_group2 = df_results.loc[(df_results[\"model_type\"] == \"medical\") & (\n",
    "    df_results[\"trainable_module\"] != \"ML\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RQ1, SLAKE: U=8.0, p=0.8238095238095238, prob=0.3333333333333333\n",
      "RQ1, PathVQA: U=5.0, p=0.9428571428571428, prob=0.20833333333333334\n",
      "RQ1, VQA-RAD: U=8.0, p=0.8238095238095238, prob=0.3333333333333333\n",
      "RQ1, Harvard-FairVLMed10k: U=4.0, p=0.9666666666666667, prob=0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "for dataset in df_results[\"dataset\"].unique():\n",
    "    plot_raincloud(\n",
    "        df_group1,\n",
    "        df_group2,\n",
    "        dataset=dataset,\n",
    "        filename=f\"RQ1_{dataset}\",\n",
    "        legend_label=[\"Off-the-shelf General\", \"Off-the-shelf Medical\"],\n",
    "    )\n",
    "\n",
    "    U, p, prob = stat_test(df_group1, df_group2,\n",
    "                           dataset=dataset, alternative=\"greater\")\n",
    "    print(f\"RQ1, {dataset}: U={U}, p={p}, prob={prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group1 = df_results.loc[(df_results[\"model_type\"] == \"general\") & (\n",
    "    df_results[\"trainable_module\"] == \"ML\")]\n",
    "df_group2 = df_results.loc[(df_results[\"model_type\"] == \"medical\") & (\n",
    "    df_results[\"trainable_module\"] != \"ML\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RQ2, SLAKE: U=13.0, p=0.2777777777777778, prob=0.65\n",
      "RQ2, PathVQA: U=22.5, p=0.016238201236439122, prob=0.9375\n",
      "RQ2, VQA-RAD: U=5.0, p=0.9047619047619049, prob=0.25\n",
      "RQ2, Harvard-FairVLMed10k: U=16.0, p=0.014285714285714285, prob=1.0\n"
     ]
    }
   ],
   "source": [
    "for dataset in df_results[\"dataset\"].unique():\n",
    "    plot_raincloud(\n",
    "        df_group1,\n",
    "        df_group2,\n",
    "        dataset=dataset,\n",
    "        filename=f\"RQ2_{dataset}\",\n",
    "        legend_label=[\"Tuned General\", \"Off-the-shelf Medical\"],\n",
    "    )\n",
    "\n",
    "    U, p, prob = stat_test(df_group1, df_group2, dataset=dataset, alternative=\"greater\")\n",
    "    print(f\"RQ2, {dataset}: U={U}, p={p}, prob={prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group1 = df_results.loc[(df_results[\"model_type\"] == \"general\") & (\n",
    "    df_results[\"trainable_module\"] == \"ML\")]\n",
    "df_group2 = df_results.loc[(df_results[\"model_type\"] == \"medical\") & (\n",
    "    df_results[\"trainable_module\"] == \"ML\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RQ3, SLAKE: U=13.0, p=0.2777777777777778, prob=0.65\n",
      "RQ3, PathVQA: U=13.5, p=0.14983857960279828, prob=0.75\n",
      "RQ3, VQA-RAD: U=8.0, p=0.5, prob=0.5333333333333333\n",
      "RQ3, Harvard-FairVLMed10k: U=8.0, p=0.3142857142857143, prob=0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "for dataset in df_results[\"dataset\"].unique():\n",
    "    plot_raincloud(\n",
    "        df_group1,\n",
    "        df_group2,\n",
    "        dataset=dataset,\n",
    "        filename=f\"RQ3_{dataset}\",\n",
    "        legend_label=[\"Tuned General\", \"Tuned Medical\"],\n",
    "    )\n",
    "\n",
    "    U, p, prob = stat_test(df_group1, df_group2,\n",
    "                           dataset=dataset, alternative=\"greater\")\n",
    "    print(f\"RQ3, {dataset}: U={U}, p={p}, prob={prob}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlmbenchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
