{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import tqdm\n",
    "import os\n",
    "import json\n",
    "\n",
    "client = OpenAI(api_key=\"sk-WeX73uM3ERd6f7kF6b373aFbE62544B1A06fEf93C67156B6\",\n",
    "                base_url=\"https://api.emabc.xyz/v1\")\n",
    "\n",
    "TEMPLATE = \"\"\"请总结该医疗报告中的诊断关键词，以分号分隔：\n",
    "\n",
    "{}\n",
    "\"\"\"\n",
    "\n",
    "CONTEXT_NA = \"No context available.\"\n",
    "\n",
    "\n",
    "def add_message_to_history(dialogue_history, role, content):\n",
    "    \"\"\"将消息添加到对话历史中。\"\"\"\n",
    "    dialogue_history.append({\"role\": role, \"content\": content})\n",
    "\n",
    "\n",
    "def generate_response(prompt):\n",
    "    \"\"\"使用 OpenAI GPT-4 生成回复。\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\", messages=prompt, temperature=1.0, stop=\"\"  # 确保使用正确的引擎名\n",
    "    )\n",
    "\n",
    "    message = response.choices[0].message.content\n",
    "    # function_call = response.choices[0].message.tool_calls\n",
    "    return message\n",
    "\n",
    "\n",
    "def create_prompt_from_history(dialogue_history, instruction=\"\"):\n",
    "    \"\"\"从对话历史中创建提示文本。\"\"\"\n",
    "\n",
    "    prompt = [{\"role\": \"system\", \"content\": instruction}]\n",
    "    for entry in dialogue_history:\n",
    "        prompt.append({\"role\": entry[\"role\"], \"content\": entry[\"content\"]})\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def get_gpt4_response(dialogue_history, instruction=\"\"):\n",
    "    prompt = create_prompt_from_history(dialogue_history, instruction)\n",
    "    message = generate_response(prompt)\n",
    "    return message\n",
    "\n",
    "\n",
    "def get_client():\n",
    "\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "def get_gpt4_response(dialogue_history, instruction=\"\"):\n",
    "    prompt = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": instruction,\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    for entry in dialogue_history:\n",
    "        prompt.append({\"role\": entry[\"role\"], \"content\": entry[\"content\"]})\n",
    "\n",
    "    response = requests.post(\n",
    "        url=\"https://openrouter.ai/api/v1/chat/completions\",\n",
    "        headers={\n",
    "            \"Authorization\": \"Bearer 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\",\n",
    "        },\n",
    "        data=json.dumps({\"model\": \"openai/gpt-4o\", \"messages\": prompt}),  # Optional\n",
    "    )\n",
    "\n",
    "    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "def get_ds_response(dialogue_history, instruction=\"\"):\n",
    "    prompt = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": instruction,\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    for entry in dialogue_history:\n",
    "        prompt.append({\"role\": entry[\"role\"], \"content\": entry[\"content\"]})\n",
    "\n",
    "    response = requests.post(\n",
    "        url=\"https://openrouter.ai/api/v1/chat/completions\",\n",
    "        headers={\n",
    "            \"Authorization\": \"Bearer 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\",\n",
    "        },\n",
    "        data=json.dumps({\"model\": \"deepseek/deepseek-r1:free\", \"messages\": prompt}),  # Optional\n",
    "    )\n",
    "\n",
    "    return response.json()[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = \"what are positively charged, thus allowing the compaction of the negatively charged dna?\"\n",
    "ans = \"the histone subunits\"\n",
    "pred = \"the protein components of the replication fork\"\n",
    "\n",
    "prompt = \"We would like to request your feedback on the performance of the AI assistant in response to the user question displayed above, with reference to the provided ground truth answer. Please rate the helpfulness, relevance, accuracy, and level of detail of the assistant's response. Assign an overall score on a scale of 1 to 100, where a higher score indicates better overall performance. Please first output a single line containing only the score (a single numeric value). In the subsequent line, please provide a comprehensive explanation of your evaluation, referencing the ground truth answer to justify your score. Ensure your judgment is unbiased and objective.\"\n",
    "\n",
    "query = (\n",
    "    f\"[Question]\\n{qs}\\n\\n\"\n",
    "    f\"[True Answer]\\n{ans}\\n\\n[End of True Answer]\\n\\n\"\n",
    "    f\"[Prediction]\\n{pred}\\n\\n[End of prediction]\\n\\n\"\n",
    "    f\"[System]\\n{prompt}\\n\\n\"\n",
    ")\n",
    "\n",
    "instruction = \"You are a helpful and precise assistant for checking the quality of the answer of medical VQA task\"\n",
    "\n",
    "dialogue_history = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": query,\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_ds_response(dialogue_history, instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10  \\nThe prediction incorrectly identifies \"the protein components of the replication fork\" as the answer, which is unrelated to the question. The true answer, histone subunits, are positively charged proteins that enable DNA compaction by binding to its negatively charged phosphate backbone. Replication fork proteins (e.g., helicase, DNA polymerase) are involved in DNA replication, not compaction, and lack the functional or structural relevance to the charge-based interaction described in the question. The prediction is entirely off-topic and incorrect, resulting in low scores for accuracy, relevance, and helpfulness.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The prediction incorrectly identifies \"the protein components of the replication fork\" as the answer, which is unrelated to the question. The true answer, histone subunits, are positively charged proteins that enable DNA compaction by binding to its negatively charged phosphate backbone. Replication fork proteins (e.g., helicase, DNA polymerase) are involved in DNA replication, not compaction, and lack the functional or structural relevance to the charge-based interaction described in the question. The prediction is entirely off-topic and incorrect, resulting in low scores for accuracy, relevance, and helpfulness.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score, reason = response.split(\"\\n\")\n",
    "\n",
    "score = float(score)\n",
    "\n",
    "reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt):\n",
    "    \"\"\"使用 OpenAI GPT-4 生成回复。\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\", messages=prompt, temperature=1.0, stop=\"\"  # 确保使用正确的引擎名\n",
    "    )\n",
    "\n",
    "    message = response.choices[0].message.content\n",
    "    # function_call = response.choices[0].message.tool_calls\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type bytes is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/yesindeed/Documents/Research/codes/ours/MedVLMBench/notebooks/yuan/analyze/test_gpt_eval.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/yesindeed/Documents/Research/codes/ours/MedVLMBench/notebooks/yuan/analyze/test_gpt_eval.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m generate_response(response)\n",
      "\u001b[1;32m/home/yesindeed/Documents/Research/codes/ours/MedVLMBench/notebooks/yuan/analyze/test_gpt_eval.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yesindeed/Documents/Research/codes/ours/MedVLMBench/notebooks/yuan/analyze/test_gpt_eval.ipynb#W5sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_response\u001b[39m(prompt):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yesindeed/Documents/Research/codes/ours/MedVLMBench/notebooks/yuan/analyze/test_gpt_eval.ipynb#W5sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"使用 OpenAI GPT-4 生成回复。\"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/yesindeed/Documents/Research/codes/ours/MedVLMBench/notebooks/yuan/analyze/test_gpt_eval.ipynb#W5sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mchat\u001b[39m.\u001b[39mcompletions\u001b[39m.\u001b[39mcreate(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yesindeed/Documents/Research/codes/ours/MedVLMBench/notebooks/yuan/analyze/test_gpt_eval.ipynb#W5sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m         model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpt-4o\u001b[39m\u001b[39m\"\u001b[39m, messages\u001b[39m=\u001b[39mprompt, temperature\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m, stop\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# 确保使用正确的引擎名\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yesindeed/Documents/Research/codes/ours/MedVLMBench/notebooks/yuan/analyze/test_gpt_eval.ipynb#W5sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yesindeed/Documents/Research/codes/ours/MedVLMBench/notebooks/yuan/analyze/test_gpt_eval.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     message \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yesindeed/Documents/Research/codes/ours/MedVLMBench/notebooks/yuan/analyze/test_gpt_eval.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39m# function_call = response.choices[0].message.tool_calls\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/vlmbenchmark/lib/python3.11/site-packages/openai/_utils/_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m             msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing required argument: \u001b[39m\u001b[39m{\u001b[39;00mquote(missing[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 274\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/vlmbenchmark/lib/python3.11/site-packages/openai/resources/chat/completions.py:815\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[39m@required_args\u001b[39m([\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], [\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    776\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    777\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m     timeout: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m httpx\u001b[39m.\u001b[39mTimeout \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m NotGiven \u001b[39m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    813\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ChatCompletion \u001b[39m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    814\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 815\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post(\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m/chat/completions\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    817\u001b[0m         body\u001b[39m=\u001b[39mmaybe_transform(\n\u001b[1;32m    818\u001b[0m             {\n\u001b[1;32m    819\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m: messages,\n\u001b[1;32m    820\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m: model,\n\u001b[1;32m    821\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39maudio\u001b[39m\u001b[39m\"\u001b[39m: audio,\n\u001b[1;32m    822\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mfrequency_penalty\u001b[39m\u001b[39m\"\u001b[39m: frequency_penalty,\n\u001b[1;32m    823\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mfunction_call\u001b[39m\u001b[39m\"\u001b[39m: function_call,\n\u001b[1;32m    824\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mfunctions\u001b[39m\u001b[39m\"\u001b[39m: functions,\n\u001b[1;32m    825\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mlogit_bias\u001b[39m\u001b[39m\"\u001b[39m: logit_bias,\n\u001b[1;32m    826\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mlogprobs\u001b[39m\u001b[39m\"\u001b[39m: logprobs,\n\u001b[1;32m    827\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mmax_completion_tokens\u001b[39m\u001b[39m\"\u001b[39m: max_completion_tokens,\n\u001b[1;32m    828\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mmax_tokens\u001b[39m\u001b[39m\"\u001b[39m: max_tokens,\n\u001b[1;32m    829\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m: metadata,\n\u001b[1;32m    830\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mmodalities\u001b[39m\u001b[39m\"\u001b[39m: modalities,\n\u001b[1;32m    831\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mn\u001b[39m\u001b[39m\"\u001b[39m: n,\n\u001b[1;32m    832\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mparallel_tool_calls\u001b[39m\u001b[39m\"\u001b[39m: parallel_tool_calls,\n\u001b[1;32m    833\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mpresence_penalty\u001b[39m\u001b[39m\"\u001b[39m: presence_penalty,\n\u001b[1;32m    834\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mresponse_format\u001b[39m\u001b[39m\"\u001b[39m: response_format,\n\u001b[1;32m    835\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mseed\u001b[39m\u001b[39m\"\u001b[39m: seed,\n\u001b[1;32m    836\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mservice_tier\u001b[39m\u001b[39m\"\u001b[39m: service_tier,\n\u001b[1;32m    837\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mstop\u001b[39m\u001b[39m\"\u001b[39m: stop,\n\u001b[1;32m    838\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mstore\u001b[39m\u001b[39m\"\u001b[39m: store,\n\u001b[1;32m    839\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m: stream,\n\u001b[1;32m    840\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mstream_options\u001b[39m\u001b[39m\"\u001b[39m: stream_options,\n\u001b[1;32m    841\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mtemperature\u001b[39m\u001b[39m\"\u001b[39m: temperature,\n\u001b[1;32m    842\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mtool_choice\u001b[39m\u001b[39m\"\u001b[39m: tool_choice,\n\u001b[1;32m    843\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mtools\u001b[39m\u001b[39m\"\u001b[39m: tools,\n\u001b[1;32m    844\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mtop_logprobs\u001b[39m\u001b[39m\"\u001b[39m: top_logprobs,\n\u001b[1;32m    845\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mtop_p\u001b[39m\u001b[39m\"\u001b[39m: top_p,\n\u001b[1;32m    846\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m: user,\n\u001b[1;32m    847\u001b[0m             },\n\u001b[1;32m    848\u001b[0m             completion_create_params\u001b[39m.\u001b[39mCompletionCreateParams,\n\u001b[1;32m    849\u001b[0m         ),\n\u001b[1;32m    850\u001b[0m         options\u001b[39m=\u001b[39mmake_request_options(\n\u001b[1;32m    851\u001b[0m             extra_headers\u001b[39m=\u001b[39mextra_headers, extra_query\u001b[39m=\u001b[39mextra_query, extra_body\u001b[39m=\u001b[39mextra_body, timeout\u001b[39m=\u001b[39mtimeout\n\u001b[1;32m    852\u001b[0m         ),\n\u001b[1;32m    853\u001b[0m         cast_to\u001b[39m=\u001b[39mChatCompletion,\n\u001b[1;32m    854\u001b[0m         stream\u001b[39m=\u001b[39mstream \u001b[39mor\u001b[39;00m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    855\u001b[0m         stream_cls\u001b[39m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[1;32m    856\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/vlmbenchmark/lib/python3.11/site-packages/openai/_base_client.py:1277\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[1;32m   1264\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1265\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1272\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1273\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m   1274\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[1;32m   1275\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[1;32m   1276\u001b[0m     )\n\u001b[0;32m-> 1277\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest(cast_to, opts, stream\u001b[39m=\u001b[39mstream, stream_cls\u001b[39m=\u001b[39mstream_cls))\n",
      "File \u001b[0;32m~/anaconda3/envs/vlmbenchmark/lib/python3.11/site-packages/openai/_base_client.py:954\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    952\u001b[0m     retries_taken \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 954\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_request(\n\u001b[1;32m    955\u001b[0m     cast_to\u001b[39m=\u001b[39mcast_to,\n\u001b[1;32m    956\u001b[0m     options\u001b[39m=\u001b[39moptions,\n\u001b[1;32m    957\u001b[0m     stream\u001b[39m=\u001b[39mstream,\n\u001b[1;32m    958\u001b[0m     stream_cls\u001b[39m=\u001b[39mstream_cls,\n\u001b[1;32m    959\u001b[0m     retries_taken\u001b[39m=\u001b[39mretries_taken,\n\u001b[1;32m    960\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/vlmbenchmark/lib/python3.11/site-packages/openai/_base_client.py:980\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    977\u001b[0m options \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_options(options)\n\u001b[1;32m    979\u001b[0m remaining_retries \u001b[39m=\u001b[39m options\u001b[39m.\u001b[39mget_max_retries(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_retries) \u001b[39m-\u001b[39m retries_taken\n\u001b[0;32m--> 980\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_request(options, retries_taken\u001b[39m=\u001b[39mretries_taken)\n\u001b[1;32m    981\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_request(request)\n\u001b[1;32m    983\u001b[0m kwargs: HttpxSendArgs \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/anaconda3/envs/vlmbenchmark/lib/python3.11/site-packages/openai/_base_client.py:505\u001b[0m, in \u001b[0;36mBaseClient._build_request\u001b[0;34m(self, options, retries_taken)\u001b[0m\n\u001b[1;32m    502\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mextensions\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39msni_hostname\u001b[39m\u001b[39m\"\u001b[39m: prepared_url\u001b[39m.\u001b[39mhost\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m)}\n\u001b[1;32m    504\u001b[0m \u001b[39m# TODO: report this error to httpx\u001b[39;00m\n\u001b[0;32m--> 505\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39mbuild_request(  \u001b[39m# pyright: ignore[reportUnknownMemberType]\u001b[39;00m\n\u001b[1;32m    506\u001b[0m     headers\u001b[39m=\u001b[39mheaders,\n\u001b[1;32m    507\u001b[0m     timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(options\u001b[39m.\u001b[39mtimeout, NotGiven) \u001b[39melse\u001b[39;00m options\u001b[39m.\u001b[39mtimeout,\n\u001b[1;32m    508\u001b[0m     method\u001b[39m=\u001b[39moptions\u001b[39m.\u001b[39mmethod,\n\u001b[1;32m    509\u001b[0m     url\u001b[39m=\u001b[39mprepared_url,\n\u001b[1;32m    510\u001b[0m     \u001b[39m# the `Query` type that we use is incompatible with qs'\u001b[39;00m\n\u001b[1;32m    511\u001b[0m     \u001b[39m# `Params` type as it needs to be typed as `Mapping[str, object]`\u001b[39;00m\n\u001b[1;32m    512\u001b[0m     \u001b[39m# so that passing a `TypedDict` doesn't cause an error.\u001b[39;00m\n\u001b[1;32m    513\u001b[0m     \u001b[39m# https://github.com/microsoft/pyright/issues/3526#event-6715453066\u001b[39;00m\n\u001b[1;32m    514\u001b[0m     params\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mqs\u001b[39m.\u001b[39mstringify(cast(Mapping[\u001b[39mstr\u001b[39m, Any], params)) \u001b[39mif\u001b[39;00m params \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    515\u001b[0m     json\u001b[39m=\u001b[39mjson_data,\n\u001b[1;32m    516\u001b[0m     files\u001b[39m=\u001b[39mfiles,\n\u001b[1;32m    517\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    518\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/vlmbenchmark/lib/python3.11/site-packages/httpx/_client.py:357\u001b[0m, in \u001b[0;36mBaseClient.build_request\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, timeout, extensions)\u001b[0m\n\u001b[1;32m    351\u001b[0m     timeout \u001b[39m=\u001b[39m (\n\u001b[1;32m    352\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout\n\u001b[1;32m    353\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(timeout, UseClientDefault)\n\u001b[1;32m    354\u001b[0m         \u001b[39melse\u001b[39;00m Timeout(timeout)\n\u001b[1;32m    355\u001b[0m     )\n\u001b[1;32m    356\u001b[0m     extensions \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mextensions, timeout\u001b[39m=\u001b[39mtimeout\u001b[39m.\u001b[39mas_dict())\n\u001b[0;32m--> 357\u001b[0m \u001b[39mreturn\u001b[39;00m Request(\n\u001b[1;32m    358\u001b[0m     method,\n\u001b[1;32m    359\u001b[0m     url,\n\u001b[1;32m    360\u001b[0m     content\u001b[39m=\u001b[39mcontent,\n\u001b[1;32m    361\u001b[0m     data\u001b[39m=\u001b[39mdata,\n\u001b[1;32m    362\u001b[0m     files\u001b[39m=\u001b[39mfiles,\n\u001b[1;32m    363\u001b[0m     json\u001b[39m=\u001b[39mjson,\n\u001b[1;32m    364\u001b[0m     params\u001b[39m=\u001b[39mparams,\n\u001b[1;32m    365\u001b[0m     headers\u001b[39m=\u001b[39mheaders,\n\u001b[1;32m    366\u001b[0m     cookies\u001b[39m=\u001b[39mcookies,\n\u001b[1;32m    367\u001b[0m     extensions\u001b[39m=\u001b[39mextensions,\n\u001b[1;32m    368\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/vlmbenchmark/lib/python3.11/site-packages/httpx/_models.py:340\u001b[0m, in \u001b[0;36mRequest.__init__\u001b[0;34m(self, method, url, params, headers, cookies, content, data, files, json, stream, extensions)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[39mif\u001b[39;00m stream \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    339\u001b[0m     content_type: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcontent-type\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 340\u001b[0m     headers, stream \u001b[39m=\u001b[39m encode_request(\n\u001b[1;32m    341\u001b[0m         content\u001b[39m=\u001b[39mcontent,\n\u001b[1;32m    342\u001b[0m         data\u001b[39m=\u001b[39mdata,\n\u001b[1;32m    343\u001b[0m         files\u001b[39m=\u001b[39mfiles,\n\u001b[1;32m    344\u001b[0m         json\u001b[39m=\u001b[39mjson,\n\u001b[1;32m    345\u001b[0m         boundary\u001b[39m=\u001b[39mget_multipart_boundary_from_content_type(\n\u001b[1;32m    346\u001b[0m             content_type\u001b[39m=\u001b[39mcontent_type\u001b[39m.\u001b[39mencode(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mencoding)\n\u001b[1;32m    347\u001b[0m             \u001b[39mif\u001b[39;00m content_type\n\u001b[1;32m    348\u001b[0m             \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    349\u001b[0m         ),\n\u001b[1;32m    350\u001b[0m     )\n\u001b[1;32m    351\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare(headers)\n\u001b[1;32m    352\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream \u001b[39m=\u001b[39m stream\n",
      "File \u001b[0;32m~/anaconda3/envs/vlmbenchmark/lib/python3.11/site-packages/httpx/_content.py:212\u001b[0m, in \u001b[0;36mencode_request\u001b[0;34m(content, data, files, json, boundary)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[39mreturn\u001b[39;00m encode_urlencoded_data(data)\n\u001b[1;32m    211\u001b[0m \u001b[39melif\u001b[39;00m json \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 212\u001b[0m     \u001b[39mreturn\u001b[39;00m encode_json(json)\n\u001b[1;32m    214\u001b[0m \u001b[39mreturn\u001b[39;00m {}, ByteStream(\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/vlmbenchmark/lib/python3.11/site-packages/httpx/_content.py:175\u001b[0m, in \u001b[0;36mencode_json\u001b[0;34m(json)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencode_json\u001b[39m(json: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mtuple\u001b[39m[\u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m], ByteStream]:\n\u001b[0;32m--> 175\u001b[0m     body \u001b[39m=\u001b[39m json_dumps(json)\u001b[39m.\u001b[39mencode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    176\u001b[0m     content_length \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mlen\u001b[39m(body))\n\u001b[1;32m    177\u001b[0m     content_type \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mapplication/json\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/vlmbenchmark/lib/python3.11/json/__init__.py:231\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[39m# cached encoder\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m skipkeys \u001b[39mand\u001b[39;00m ensure_ascii \u001b[39mand\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     check_circular \u001b[39mand\u001b[39;00m allow_nan \u001b[39mand\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m indent \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m separators \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     default \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m sort_keys \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[0;32m--> 231\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_encoder\u001b[39m.\u001b[39mencode(obj)\n\u001b[1;32m    232\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONEncoder\n",
      "File \u001b[0;32m~/anaconda3/envs/vlmbenchmark/lib/python3.11/json/encoder.py:200\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[39mreturn\u001b[39;00m encode_basestring(o)\n\u001b[1;32m    197\u001b[0m \u001b[39m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterencode(o, _one_shot\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    201\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(chunks, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m    202\u001b[0m     chunks \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(chunks)\n",
      "File \u001b[0;32m~/anaconda3/envs/vlmbenchmark/lib/python3.11/json/encoder.py:258\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    254\u001b[0m     _iterencode \u001b[39m=\u001b[39m _make_iterencode(\n\u001b[1;32m    255\u001b[0m         markers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault, _encoder, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindent, floatstr,\n\u001b[1;32m    256\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey_separator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_separator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msort_keys,\n\u001b[1;32m    257\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mskipkeys, _one_shot)\n\u001b[0;32m--> 258\u001b[0m \u001b[39mreturn\u001b[39;00m _iterencode(o, \u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/vlmbenchmark/lib/python3.11/json/encoder.py:180\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault\u001b[39m(\u001b[39mself\u001b[39m, o):\n\u001b[1;32m    162\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \n\u001b[1;32m    179\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mObject of type \u001b[39m\u001b[39m{\u001b[39;00mo\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    181\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mis not JSON serializable\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type bytes is not JSON serializable"
     ]
    }
   ],
   "source": [
    "generate_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlmbenchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
