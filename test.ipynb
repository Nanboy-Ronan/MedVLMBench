{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logger is not set.\n"
     ]
    }
   ],
   "source": [
    "from easydict import EasyDict as edict\n",
    "from dataset import get_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_args = edict(\n",
    "    split=\"train\",\n",
    "    task=\"vqa\",\n",
    "    dataset=\"MedXpertQA\",\n",
    "    seed=0,\n",
    "    image_path=\"/media/yesindeed/DATADRIVE1/mount/remote_cse/datasets/MedXpertQA\",\n",
    ")\n",
    "\n",
    "dataset = get_dataset(data_args)\n",
    "data_loader = DataLoader(dataset, batch_size=1,\n",
    "                         collate_fn=lambda batch: batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': [tensor([[[  0,   0,   0,  ...,  21,  17,  18],\n",
       "           [  0,   0,   0,  ...,  23,  19,  19],\n",
       "           [  0,   0,   0,  ...,  18,  16,  12],\n",
       "           ...,\n",
       "           [  0,   0,   0,  ..., 132, 125, 143],\n",
       "           [  0,   0,   0,  ..., 140, 133, 146],\n",
       "           [  0,   0,   0,  ..., 155, 147, 164]],\n",
       "  \n",
       "          [[  0,   0,   0,  ...,  21,  17,  18],\n",
       "           [  0,   0,   0,  ...,  23,  19,  19],\n",
       "           [  0,   0,   0,  ...,  18,  16,  12],\n",
       "           ...,\n",
       "           [  0,   0,   0,  ..., 132, 125, 143],\n",
       "           [  0,   0,   0,  ..., 140, 133, 146],\n",
       "           [  0,   0,   0,  ..., 155, 147, 164]],\n",
       "  \n",
       "          [[  0,   0,   0,  ...,  21,  17,  18],\n",
       "           [  0,   0,   0,  ...,  23,  19,  19],\n",
       "           [  0,   0,   0,  ...,  18,  16,  12],\n",
       "           ...,\n",
       "           [  0,   0,   0,  ..., 132, 125, 143],\n",
       "           [  0,   0,   0,  ..., 140, 133, 146],\n",
       "           [  0,   0,   0,  ..., 155, 147, 164]]], dtype=torch.uint8),\n",
       "  tensor([[[114, 102, 101,  ..., 170, 175, 172],\n",
       "           [114, 115, 126,  ..., 183, 185, 179],\n",
       "           [101, 107, 130,  ..., 176, 175, 167],\n",
       "           ...,\n",
       "           [143, 152, 142,  ..., 145, 145, 139],\n",
       "           [137, 143, 144,  ..., 143, 142, 140],\n",
       "           [124, 127, 132,  ..., 144, 142, 140]],\n",
       "  \n",
       "          [[ 71,  71,  86,  ..., 139, 145, 138],\n",
       "           [ 73,  83, 107,  ..., 150, 152, 143],\n",
       "           [ 67,  75, 105,  ..., 144, 144, 135],\n",
       "           ...,\n",
       "           [108, 115, 107,  ..., 116, 117, 115],\n",
       "           [111, 113, 117,  ..., 114, 116, 112],\n",
       "           [102, 103, 111,  ..., 114, 116, 109]],\n",
       "  \n",
       "          [[161, 160, 164,  ..., 196, 202, 200],\n",
       "           [162, 177, 190,  ..., 211, 213, 209],\n",
       "           [154, 166, 186,  ..., 205, 205, 198],\n",
       "           ...,\n",
       "           [176, 184, 170,  ..., 190, 190, 183],\n",
       "           [176, 183, 181,  ..., 189, 189, 182],\n",
       "           [166, 171, 174,  ..., 191, 190, 181]]], dtype=torch.uint8)],\n",
       " 'query': 'A 60-year-old female complains of progressive right hip pain.  A pelvis radiograph is shown in Figure A and a biopsy specimen is shown in Figure B.  What is the most appropriate treatment?\\nAnswer Choices: (A) Radiation therapy (B) Chemotherapy followed by radiation therapy (C) Wide surgical resection (D) Neoadjuvant chemotherapy followed by surgery followed by adjuvant chemotherapy (E) Neoadjuvant radiation followed by surgical resection',\n",
       " 'label': 'C',\n",
       " 'is_open': False,\n",
       " 'prompt_template': '{}\\nAnswer with the single letter corresponding to the best choice.',\n",
       " 'image_size': [(508, 450), (726, 450)],\n",
       " 'image_path': '/media/yesindeed/DATADRIVE1/mount/remote_cse/datasets/MedXpertQA/images/MM-805-a.jpeg;/media/yesindeed/DATADRIVE1/mount/remote_cse/datasets/MedXpertQA/images/MM-805-b.jpeg',\n",
       " 'image_paths': ['/media/yesindeed/DATADRIVE1/mount/remote_cse/datasets/MedXpertQA/images/MM-805-a.jpeg',\n",
       "  '/media/yesindeed/DATADRIVE1/mount/remote_cse/datasets/MedXpertQA/images/MM-805-b.jpeg']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[  0,   0,   0,  ...,  21,  17,  18],\n",
       "          [  0,   0,   0,  ...,  23,  19,  19],\n",
       "          [  0,   0,   0,  ...,  18,  16,  12],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ..., 132, 125, 143],\n",
       "          [  0,   0,   0,  ..., 140, 133, 146],\n",
       "          [  0,   0,   0,  ..., 155, 147, 164]],\n",
       " \n",
       "         [[  0,   0,   0,  ...,  21,  17,  18],\n",
       "          [  0,   0,   0,  ...,  23,  19,  19],\n",
       "          [  0,   0,   0,  ...,  18,  16,  12],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ..., 132, 125, 143],\n",
       "          [  0,   0,   0,  ..., 140, 133, 146],\n",
       "          [  0,   0,   0,  ..., 155, 147, 164]],\n",
       " \n",
       "         [[  0,   0,   0,  ...,  21,  17,  18],\n",
       "          [  0,   0,   0,  ...,  23,  19,  19],\n",
       "          [  0,   0,   0,  ...,  18,  16,  12],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ..., 132, 125, 143],\n",
       "          [  0,   0,   0,  ..., 140, 133, 146],\n",
       "          [  0,   0,   0,  ..., 155, 147, 164]]], dtype=torch.uint8),\n",
       " tensor([[[114, 102, 101,  ..., 170, 175, 172],\n",
       "          [114, 115, 126,  ..., 183, 185, 179],\n",
       "          [101, 107, 130,  ..., 176, 175, 167],\n",
       "          ...,\n",
       "          [143, 152, 142,  ..., 145, 145, 139],\n",
       "          [137, 143, 144,  ..., 143, 142, 140],\n",
       "          [124, 127, 132,  ..., 144, 142, 140]],\n",
       " \n",
       "         [[ 71,  71,  86,  ..., 139, 145, 138],\n",
       "          [ 73,  83, 107,  ..., 150, 152, 143],\n",
       "          [ 67,  75, 105,  ..., 144, 144, 135],\n",
       "          ...,\n",
       "          [108, 115, 107,  ..., 116, 117, 115],\n",
       "          [111, 113, 117,  ..., 114, 116, 112],\n",
       "          [102, 103, 111,  ..., 114, 116, 109]],\n",
       " \n",
       "         [[161, 160, 164,  ..., 196, 202, 200],\n",
       "          [162, 177, 190,  ..., 211, 213, 209],\n",
       "          [154, 166, 186,  ..., 205, 205, 198],\n",
       "          ...,\n",
       "          [176, 184, 170,  ..., 190, 190, 183],\n",
       "          [176, 183, 181,  ..., 189, 189, 182],\n",
       "          [166, 171, 174,  ..., 191, 190, 181]]], dtype=torch.uint8)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in data_loader:\n",
    "    break\n",
    "\n",
    "batch[\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batch[\"image\"]) == list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlmbenchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
